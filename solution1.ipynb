{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8635527,"sourceType":"datasetVersion","datasetId":5171133}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch langchain rank-bm25 wikipedia\n!pip install rank_bm25 nltk\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T06:36:16.646393Z","iopub.execute_input":"2024-06-09T06:36:16.647184Z","iopub.status.idle":"2024-06-09T06:36:41.614669Z","shell.execute_reply.started":"2024-06-09T06:36:16.647110Z","shell.execute_reply":"2024-06-09T06:36:41.613040Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.3)\nRequirement already satisfied: rank-bm25 in /opt/conda/lib/python3.10/site-packages (0.2.2)\nRequirement already satisfied: wikipedia in /opt/conda/lib/python3.10/site-packages (1.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.5)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.75)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (4.12.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\nRequirement already satisfied: rank_bm25 in /opt/conda/lib/python3.10/site-packages (0.2.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rank_bm25) (1.26.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\nimport os\n\nimport json\nimport re\nimport nltk\nfrom rank_bm25 import BM25Okapi\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:41.617243Z","iopub.execute_input":"2024-06-09T06:36:41.617673Z","iopub.status.idle":"2024-06-09T06:36:41.629500Z","shell.execute_reply.started":"2024-06-09T06:36:41.617633Z","shell.execute_reply":"2024-06-09T06:36:41.628477Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"(NOT USED, simple implementation used earlier) simply find keywords in title","metadata":{}},{"cell_type":"code","source":"import json\nimport re\n\n# Load the JSON file\nwith open('/kaggle/input/intern-json/news.article.json', 'r') as file:\n    articles = json.load(file)\n\n# Function to clean the text\ndef clean_text(text):\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters\n    return text.strip()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:41.630945Z","iopub.execute_input":"2024-06-09T06:36:41.631314Z","iopub.status.idle":"2024-06-09T06:36:44.954183Z","shell.execute_reply.started":"2024-06-09T06:36:41.631284Z","shell.execute_reply":"2024-06-09T06:36:44.953042Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Clean the articles\ncleaned_articles = []\nfor article in articles:\n    if 'Israel' in article['title'] or 'Hamas' in article['title']:\n        cleaned_articles.append({\n            'title': article['title'],\n            'articleBody': clean_text(article['articleBody'])\n        })","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:44.956621Z","iopub.execute_input":"2024-06-09T06:36:44.956961Z","iopub.status.idle":"2024-06-09T06:36:50.029430Z","shell.execute_reply.started":"2024-06-09T06:36:44.956933Z","shell.execute_reply":"2024-06-09T06:36:50.028241Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"cleaned_articles[25]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.031084Z","iopub.execute_input":"2024-06-09T06:36:50.031582Z","iopub.status.idle":"2024-06-09T06:36:50.039759Z","shell.execute_reply.started":"2024-06-09T06:36:50.031539Z","shell.execute_reply":"2024-06-09T06:36:50.038524Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'title': 'Israel Hamas War: French President Emmanuel Macron Visits Israel, Meets President Isaac Herzog',\n 'articleBody': 'Israel Hamas War French President Emmanuel Macron on meeting with Israeli President Isaac Herzog in Tel Aviv today said that he is there to express support and solidarity What happened on October 7 was a terrorist attack against your people and your nation he said French President Emmanuel Macron arrived in Tel Aviv on Tuesday to express his countrys full solidarity with Israel after the deadly October 7 attacks by Palestinian militant group Hamas The war is the deadliest of five Gaza wars for both sides The Hamasrun Health Ministry said Monday that at least 5087 Palestinians have been killed and 15270 wounded In the occupied West Bank 96 Palestinians have been killed and 1650 wounded in violence and Israeli raids since Oct 7 More than 1400 people in Israel have been killed'}"},"metadata":{}}]},{"cell_type":"code","source":"# column names are as follow, [articleBody,\tdateModified,\tscrapedDate,\tsource,\ttitle].","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.041395Z","iopub.execute_input":"2024-06-09T06:36:50.041841Z","iopub.status.idle":"2024-06-09T06:36:50.054385Z","shell.execute_reply.started":"2024-06-09T06:36:50.041802Z","shell.execute_reply":"2024-06-09T06:36:50.053149Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Document Retrieval: Top 5 Most Relevent\n\n1. The preprocess function cleans and tokenizes the text of each article.\n2. The BM25Okapi model is initialized with the tokenized articles.\n3. The retrieve_documents function scores each article based on its relevance to the query using BM25 and returns the top N articles.","metadata":{}},{"cell_type":"code","source":"# Download required NLTK data files\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.055851Z","iopub.execute_input":"2024-06-09T06:36:50.056241Z","iopub.status.idle":"2024-06-09T06:36:50.070945Z","shell.execute_reply.started":"2024-06-09T06:36:50.056205Z","shell.execute_reply":"2024-06-09T06:36:50.069616Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Function to clean and tokenize text\ndef preprocess(text):\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters\n    text = text.replace('’', \" \")  # Replace smart quotes with standard quotes\n    text = text.replace('“', '(')  # Replace other invalid characters as needed\n    text = text.replace('”', ')')\n    text = text.replace('—', '-')\n    tokens = nltk.word_tokenize(text.lower())\n    return tokens\n\ndef retrieve_documents(query, bm25, articles, n=5):\n    tokenized_query = preprocess(query)\n    doc_scores = bm25.get_scores(tokenized_query)\n    top_n_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:n]\n    return [articles[i] for i in top_n_indices]\n\n\n\ndef extract_keywords(question):\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(question)\n    keywords = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n    return keywords","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.072981Z","iopub.execute_input":"2024-06-09T06:36:50.073476Z","iopub.status.idle":"2024-06-09T06:36:50.083649Z","shell.execute_reply.started":"2024-06-09T06:36:50.073434Z","shell.execute_reply":"2024-06-09T06:36:50.082485Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en_core_web_sm')\n\ndef get_relevant_article(question):\n    print(\"getting relevent document\")\n#     # Clean and tokenize the articles\n#     tokenized_articles = [preprocess(article['articleBody']) for article in articles if 'Israel' in article['articleBody'] or 'Hamas' in article['articleBody']]\n\n    keywords = extract_keywords(question)\n#     print(keywords)\n# #     keywords = ['hamas', 'israel'] + keywords  # Add 'hamas' and 'israel' to keywords\n#     tokenized_articles = [preprocess(article['articleBody']) for article in articles if any(keyword in article['articleBody'] for keyword in keywords)]\n#     print(tokenized_articles)\n    \n    \n    filtered_articles = [article for article in articles if 'Israel' in article['title'] or 'Hamas' in article['title']]\n\n    # Apply keyword search to the filtered articles\n    tokenized_articles = [preprocess(article['articleBody']) for article in filtered_articles if any(keyword in article['articleBody'].lower() for keyword in keywords)]\n \n    # Initialize BM25\n    bm25 = BM25Okapi(tokenized_articles)\n\n    # Example question\n#     question = \"What happened at the Al-Shifa Hospital?\"\n\n    # Retrieve top 5 relevant articles\n    top_articles = retrieve_documents(question, bm25, articles, n=5)\n\n    # Print the titles of the top articles\n    for i, article in enumerate(top_articles):\n        print(f\"Article {i+1}: {article['title']}\")\n\n    # Choose the most relevant article (first one)\n    relevant_article = top_articles[0]\n    print(\"relevant_article returned - Article Length\")\n    return relevant_article","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.085520Z","iopub.execute_input":"2024-06-09T06:36:50.086209Z","iopub.status.idle":"2024-06-09T06:36:50.980001Z","shell.execute_reply.started":"2024-06-09T06:36:50.086153Z","shell.execute_reply":"2024-06-09T06:36:50.978891Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Question Answering","metadata":{}},{"cell_type":"code","source":"from transformers import BertForQuestionAnswering, BertTokenizer\nimport torch\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n\n# Load pre-trained BERT model and tokenizer\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\n\n# weight_path = \"kaporter/bert-base-uncased-finetuned-squad\"\n# # loading tokenizer\n# tokenizer = BertTokenizer.from_pretrained(weight_path)\n# #loading the model\n# model = BertForQuestionAnswering.from_pretrained(weight_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:50.983901Z","iopub.execute_input":"2024-06-09T06:36:50.984389Z","iopub.status.idle":"2024-06-09T06:36:51.996451Z","shell.execute_reply.started":"2024-06-09T06:36:50.984354Z","shell.execute_reply":"2024-06-09T06:36:51.995311Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def answer_question(question, context):\n    \n    print(\"answering question - \")\n    # Encode the question and context separately\n    \n\n    input_ids = tokenizer.encode(question, context)\n    print (f'We have about {len(input_ids)} tokens generated')\n    \n    if len(input_ids) < 512:\n        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n        #first occurence of [SEP] token\n        sep_idx = input_ids.index(tokenizer.sep_token_id)\n        #print(\"SEP token index: \", sep_idx)\n\n        num_seg_a = sep_idx+1                           #number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n        num_seg_b = len(input_ids) - num_seg_a          #number of tokens in segment B (text)\n\n        #creating the segment ids\n        segment_ids = [0]*num_seg_a + [1]*num_seg_b\n        \n        #making sure that every input token has a segment id\n        assert len(segment_ids) == len(input_ids)\n\n        output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))\n\n        #tokens with highest start and end scores\n        answer_start = torch.argmax(output.start_logits)\n        answer_end = torch.argmax(output.end_logits)\n        if answer_end >= answer_start:\n            answer = \" \".join(tokens[answer_start:answer_end+1])\n        else:\n            print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n        return answer\n\n    else:\n        answer = 'High token length, Sorry'\n        return answer","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:51.997926Z","iopub.execute_input":"2024-06-09T06:36:51.998368Z","iopub.status.idle":"2024-06-09T06:36:52.007531Z","shell.execute_reply.started":"2024-06-09T06:36:51.998318Z","shell.execute_reply":"2024-06-09T06:36:52.006444Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"question = 'Number of displaced Palestinians'\nrelevant_article = get_relevant_article(question)\n#         print(relevant_article)\nanswer = answer_question( question,relevant_article['articleBody'])\nprint(\"Answer - \", answer)\nprint()\nprint()\nquestion = 'What happened at the Al-Shifa Hospital?'\nrelevant_article = get_relevant_article(question)\n#         print(relevant_article)\nanswer = answer_question( question,relevant_article['articleBody'])\nprint(\"Answer - \", answer)\nprint()\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:36:52.008925Z","iopub.execute_input":"2024-06-09T06:36:52.009303Z","iopub.status.idle":"2024-06-09T06:37:44.723405Z","shell.execute_reply.started":"2024-06-09T06:36:52.009275Z","shell.execute_reply":"2024-06-09T06:37:44.722191Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"getting relevent document\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Article 1: Wounded Israeli tattoo artist held hostage by Hamas was operated on by a vet in Gaza, her family says\nArticle 2: Britain Condemns Iran’s Role In Red Sea Attacks\nArticle 3: COP28 Day 5 Recap: President Al Jaber's 'Fossil Fuel Science' remark, green finance and 'more declarations'\nArticle 4: Israel Asks India To Declare Hamas as a Terrorist Organisation\nArticle 5: Bank Of Israel Says In View Of The War, The Monetary Committee's…\nrelevant_article returned - Article Length\nanswering question - \nWe have about 599 tokens generated\nAnswer -  High token length, Sorry\n\n\ngetting relevent document\nArticle 1: Gaza: College Students Walk Out Calling for Israel Ceasefire\nArticle 2: UN Security Council fails again to address Israel-Hamas war, rejecting US and Russian resolutions\nArticle 3: Pentagon says a US warship commercial ships attacked in Red Sea. Houthis claim attacking 2 ships\nArticle 4: People support for Palestine can be seen after referendums\nArticle 5: Hezbollah and Israeli troops exchange fire along the border as two people are killed in Lebanon- The New Indian Express\nrelevant_article returned - Article Length\nanswering question - \nWe have about 195 tokens generated\nAnswer -  walk ##out\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"while True:\n    user_input = input(\"Enter your question ('exit' to quit): \")\n    # 1.  Number of displaced Palestinians \n    # 2.  What happened at the Al-Shifa Hospital?\n    if user_input.lower() == 'exit':\n        break\n    else:\n        question = user_input\n        relevant_article = get_relevant_article(question)\n#         print(relevant_article)\n        answer = answer_question( question,relevant_article['articleBody'])\n        print(\"Answer - \", answer)\n        print()\n        print()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T06:50:26.521742Z","iopub.execute_input":"2024-06-09T06:50:26.522333Z","iopub.status.idle":"2024-06-09T06:50:30.322744Z","shell.execute_reply.started":"2024-06-09T06:50:26.522297Z","shell.execute_reply":"2024-06-09T06:50:30.321564Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your question ('exit' to quit):  exit\n"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}