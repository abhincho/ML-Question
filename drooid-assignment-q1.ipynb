{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8655124,"sourceType":"datasetVersion","datasetId":5184909}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 📦 Install Required Packages","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install accelerate==0.21.0 transformers==4.33.1 tokenizers==0.13.3\n!pip install bitsandbytes==0.40.0 einops==0.6.1\n!pip install xformers==0.0.22.post7\n!pip install langchain==0.1.4\n!pip install faiss-gpu==1.7.1.post3\n# Install SentenceTransformers from PyPI\n!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-10T12:00:03.382598Z","iopub.execute_input":"2024-06-10T12:00:03.382975Z","iopub.status.idle":"2024-06-10T12:01:44.626054Z","shell.execute_reply.started":"2024-06-10T12:00:03.382945Z","shell.execute_reply":"2024-06-10T12:01:44.624839Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate==0.21.0 in /opt/conda/lib/python3.10/site-packages (0.21.0)\nCollecting transformers==4.33.1\n  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers==0.13.3 in /opt/conda/lib/python3.10/site-packages (0.13.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (23.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (0.23.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.1) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.1) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0) (12.5.40)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\nDownloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.31.0\n    Uninstalling transformers-4.31.0:\n      Successfully uninstalled transformers-4.31.0\nSuccessfully installed transformers-4.33.1\nRequirement already satisfied: bitsandbytes==0.40.0 in /opt/conda/lib/python3.10/site-packages (0.40.0)\nRequirement already satisfied: einops==0.6.1 in /opt/conda/lib/python3.10/site-packages (0.6.1)\nRequirement already satisfied: xformers==0.0.22.post7 in /opt/conda/lib/python3.10/site-packages (0.0.22.post7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.22.post7) (1.26.4)\nRequirement already satisfied: torch==2.1.0 in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.22.post7) (2.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers==0.0.22.post7) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers==0.0.22.post7) (12.5.40)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->xformers==0.0.22.post7) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->xformers==0.0.22.post7) (1.3.0)\nRequirement already satisfied: langchain==0.1.4 in /opt/conda/lib/python3.10/site-packages (0.1.4)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (0.6.6)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.14 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (0.0.20)\nRequirement already satisfied: langchain-core<0.2,>=0.1.16 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (0.1.23)\nRequirement already satisfied: langsmith<0.1,>=0.0.83 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (0.0.87)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.1.4) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.4) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (4.2.0)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.4) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.4) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.4) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.4) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.4) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.4) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.1.4) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.4) (3.0.3)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (1.0.0)\nRequirement already satisfied: faiss-gpu==1.7.1.post3 in /opt/conda/lib/python3.10/site-packages (1.7.1.post3)\nCollecting sentence_transformers\n  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nCollecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.23.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nCollecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nUsing cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\nUsing cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\nUsing cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\nInstalling collected packages: tokenizers, transformers, sentence_transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.1\n    Uninstalling transformers-4.33.1:\n      Successfully uninstalled transformers-4.33.1\nSuccessfully installed sentence_transformers-3.0.1 tokenizers-0.19.1 transformers-4.41.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 📂 Load the Dataset","metadata":{}},{"cell_type":"code","source":"import json\nimport re\nimport numpy as np\nimport pandas as pd\n# Load dataset\nwith open('/kaggle/input/news-articles/news.article.json', 'r') as f:\n    articles = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:27:43.232682Z","iopub.execute_input":"2024-06-10T13:27:43.233371Z","iopub.status.idle":"2024-06-10T13:27:48.226938Z","shell.execute_reply.started":"2024-06-10T13:27:43.233335Z","shell.execute_reply":"2024-06-10T13:27:48.225667Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"first_two = articles[:2]\nprint(first_two)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:28:17.887868Z","iopub.execute_input":"2024-06-10T13:28:17.889031Z","iopub.status.idle":"2024-06-10T13:28:17.894849Z","shell.execute_reply.started":"2024-06-10T13:28:17.888971Z","shell.execute_reply":"2024-06-10T13:28:17.893786Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[{'articleBody': 'Sanjay Raut, a member of the Shiv Sena (UBT) party, responded to the Maharashtra chief minister\\'s statement that Eknath Shinde \"himself is Hamas\" and that the Shiv Sena group led by Uddhav Thackeray is capable of collaborating with \"Hamas and Lashkar-e-Taiba for their own selfishness\" on Wednesday by claiming that Eknath Shinde is Hamas.\\n\\n\\n\\nRaut made fun of Shinde by claiming, \"He himself is Hamas. Hamas and Lashkar-e-Taiba, two terrorist groups, are completely irrelevant in Maharashtra. But the BJP is to blame for sowing the worms in their (the Shinde faction\\'s) thoughts, said Raut.\\n\\nWhen Shinde made a statement at the Tuesday Dussehra rally in Mumbai\\'s Azad Maidan, Raut reacted to it. As part of the opposition alliance INDIA, Uddhav Thackeray\\'s Shiv Sena (UBT) has formed an alliance with Congress and the Samajwadi Party. Shinde remarked of this alliance: \"For their own selfishness, they will tie the knot with Hamas and Lashkar-e-Taiba.\"\\n\\nRaut highlighted that Shinde\\'s address differed from the customary Dussehra rallies conducted by the Shiv Sena each year. Raut expressed that he could make various remarks, but we adhere to the principles and values of Balasaheb Thackeray. Balasaheb Thackeray used to focus on the nation and its citizens. However, Shinde\\'s entire speech was centered on bolstering the BJP, reinforcing the position of Modi ji, and fortifying JP Nadda ji.\\n\\nIn response to the provided statement, Raut expressed his view that the occasion was Dussehra, a day traditionally associated with auspiciousness. However, he criticized Shinde for focusing on contentious matters and likened him to \"Hamas\" and \"Al Qaeda of Maharashtra.\"\\n\\nRaut also mentioned that Shinde had, in his Dussehra speech, questioned the alliance between Shiv Sena (UBT) and Akhilesh Yadav\\'s Samajwadi Party, citing an incident from 1990 when Samajwadi Party founder Mulayam Singh Yadav had reportedly ordered the use of force against karsevaks in Ayodhya.\\n\\nThis event marked the first time that Thackeray and Shinde, leaders of the divergent factions of the Shiv Sena, organized separate Dussehra rallies in Mumbai, marking a departure from the party\\'s historical practices.', 'dateModified': {'$date': '2023-10-25T06:35:50.000Z'}, 'scrapedDate': {'$date': '2023-10-27T13:12:18.339Z'}, 'source': 'https://www.thehansindia.com/', 'title': \"Shiv Sena MP Sanjay Raut Responds To 'Hamas' Remark In Fiery Exchange\"}, {'articleBody': 'Kozhikode (Kerala) [India], October 27 (ANI): Pointing out that the world was witnessing its worst tragedy, Congress MP Shashi Tharoor alleged that Israel\\'s response to the October 7 Hamas terrorist attack was \"disproportionate,\" as a greater number of Palestinian people were killed in the past 19 days compared to those who lost their lives in the region since the year 2008.\\n\\nAddressing an event organised to express solidarity with the Palestine people by the Indian United Muslim League (IUML) in Kerala\\'s Kozhikode on Thursday, Tharoor urged Israel to end air strikes in Gaza adding that India has always stood for peace since Mahatama Gandhi.\\n\\n\\n\\n\"Since 19 days, the world is seeing the worst human-rights tragedies. We are seeing the worst tragedy. Terrorists attacked Israel, Hamas is a terror group. Israel stopped providing food, water and electricity to Gaza. We are condemning the bombing of Israel,\" Tharoor said at the event held at Kozhikode beach.\\n\\nTharoor, who had previoulsy served as an UN diplomat said the ongoing air strikes in Gaza by Israel in response to the Hamas attack was \"disproportionate.\" Reiterating Bapu\\'s words, Tharoor said, \"An eye for an eye will make the whole world blind. India has always stood for peace since Gandhi.\"\\n\\nHe also highlighted that the ongoing crisis is not a Muslim issue but a human rights issue and said \"war knows no religion.\"\\n\\n\"Israel calls their operation, \\'Swords of Iron\\', but now those swords are dipped in the blood of children. The bombing has caused a lot of injuries and innocent people are suffering and they are dying. Many are living under suffocating occupation,\" Tharoor said.\\n\\nHe said that over 6,000 Palestinians and 300 Isrealis were killed in clashes in the area between 2008 and September this year and the number of those who died since October 7, however, was much more.\\n\\n\"While 1,400 Israelis died in the Hamas terrorist attack, many more were killed in Gaza when Israel responded to it.....Innocent civilians are dying,\" Tharoor said.\\n\\n\\n\\nTharoor urged Israel to end the war and further appealed to the world to unite to \"end the human rights violations inflicted on the Palestinian people\". \"Now, it is more than time to announce a ceasefire,\" the Congress MP from Thiruvananthapuram said.\\n\\n\\n\\nWhile addressing the rally, IUML national general secretary PK Kunhalikutty said that the biggest weapon in the world is public opinion and that showing solidarity will bring results.\\n\\n\"Children are dying. We all are here to shed tears for the brutality in Gaza. We have no weapons to send there or save them. This rally will yield fruit because the biggest weapon in the world is public opinion. Global leaders are joining in solidarity. That\\'s how we also joined this. Solidarity has made results here. Killings should stop in Palestine,\" he said.\\n\\n\\n\\nIUML Party workers gathered in strength for Thursday\\'s rally, which was presided over by Kunhalikutty with Shashi Tharoor as Chief Guest. IUML state president Panakkad Sayyid Sadiq Ali Shihab Thangal inaugurated the rally.\\n\\nIn his speech, Thangal said \"Israel\\'s occupation has created Palestine conflict. They are trying to survive. They are trying the defend their land. Stop genocide killings. This conflict has started since 1947. Gandhi criticised Israeli occupation. Nehru, Manmohan Singh, even Vajpayee also took a stand against the Israeli occupation of Palestine... They all stood with justice. The current government is trying to dilute that stand and make Israel look holy.\"\\n\\n\"They are trying to whitewash Israel. We should stand with marginalised. India\\'s policy is to support the vulnerable people. Israel is the biggest terrorist country. Whoever is supporting Israel they are supporting terror. Justice will rise over there that\\'s why we are having this rally. With our prayers let their wounds be healed,\" the IUML leader said.\\n\\nOn attending the IUML\\'s solidarity rally, Tharoor said, \"India is one of the handful of countries that maintains ambassadors in both Israel and Palestine and enjoys good relations with both. We should be a voice for peace amid the carnage.\"\\n\\nAfter the October 7 attack on Israel from the Gaza Strip by Hamas, Israeli Prime Minister Benjamin Netanyahu set up a war cabinet and the Israeli defence minister Yoav Gallant said they will launch a ground offensive on Gaza, seeking to \"wipe off from the face of earth\" the Palestine-terror group. (ANI)\\n\\n', 'scrapedDate': {'$date': '2023-10-27T13:12:45.595Z'}, 'source': 'https://www.aninews.in/', 'title': \"At IUML's pro-Palestine rally in Kerala Tharoor calls Hamas 'terror group', urges Israel to end war\"}]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Clean the text\ndef clean_text(text):\n    text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n    return text\n\n# Apply cleaning to all articles\ncleaned_articles = [{'content': clean_text(article['articleBody'])} for article in articles]\n\nprint(f\"Total articles loaded: {len(cleaned_articles)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:28:21.173125Z","iopub.execute_input":"2024-06-10T13:28:21.173828Z","iopub.status.idle":"2024-06-10T13:28:39.462675Z","shell.execute_reply.started":"2024-06-10T13:28:21.173792Z","shell.execute_reply":"2024-06-10T13:28:39.461688Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total articles loaded: 37421\n","output_type":"stream"}]},{"cell_type":"code","source":"first_two = cleaned_articles[:2]\nprint(first_two)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:28:42.342710Z","iopub.execute_input":"2024-06-10T13:28:42.343508Z","iopub.status.idle":"2024-06-10T13:28:42.349017Z","shell.execute_reply.started":"2024-06-10T13:28:42.343469Z","shell.execute_reply":"2024-06-10T13:28:42.347891Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[{'content': 'Sanjay Raut a member of the Shiv Sena UBT party responded to the Maharashtra chief ministers statement that Eknath Shinde himself is Hamas and that the Shiv Sena group led by Uddhav Thackeray is capable of collaborating with Hamas and LashkareTaiba for their own selfishness on Wednesday by claiming that Eknath Shinde is Hamas Raut made fun of Shinde by claiming He himself is Hamas Hamas and LashkareTaiba two terrorist groups are completely irrelevant in Maharashtra But the BJP is to blame for sowing the worms in their the Shinde factions thoughts said Raut When Shinde made a statement at the Tuesday Dussehra rally in Mumbais Azad Maidan Raut reacted to it As part of the opposition alliance INDIA Uddhav Thackerays Shiv Sena UBT has formed an alliance with Congress and the Samajwadi Party Shinde remarked of this alliance For their own selfishness they will tie the knot with Hamas and LashkareTaiba Raut highlighted that Shindes address differed from the customary Dussehra rallies conducted by the Shiv Sena each year Raut expressed that he could make various remarks but we adhere to the principles and values of Balasaheb Thackeray Balasaheb Thackeray used to focus on the nation and its citizens However Shindes entire speech was centered on bolstering the BJP reinforcing the position of Modi ji and fortifying JP Nadda ji In response to the provided statement Raut expressed his view that the occasion was Dussehra a day traditionally associated with auspiciousness However he criticized Shinde for focusing on contentious matters and likened him to Hamas and Al Qaeda of Maharashtra Raut also mentioned that Shinde had in his Dussehra speech questioned the alliance between Shiv Sena UBT and Akhilesh Yadavs Samajwadi Party citing an incident from 1990 when Samajwadi Party founder Mulayam Singh Yadav had reportedly ordered the use of force against karsevaks in Ayodhya This event marked the first time that Thackeray and Shinde leaders of the divergent factions of the Shiv Sena organized separate Dussehra rallies in Mumbai marking a departure from the partys historical practices'}, {'content': 'Kozhikode Kerala India October 27 ANI Pointing out that the world was witnessing its worst tragedy Congress MP Shashi Tharoor alleged that Israels response to the October 7 Hamas terrorist attack was disproportionate as a greater number of Palestinian people were killed in the past 19 days compared to those who lost their lives in the region since the year 2008 Addressing an event organised to express solidarity with the Palestine people by the Indian United Muslim League IUML in Keralas Kozhikode on Thursday Tharoor urged Israel to end air strikes in Gaza adding that India has always stood for peace since Mahatama Gandhi Since 19 days the world is seeing the worst humanrights tragedies We are seeing the worst tragedy Terrorists attacked Israel Hamas is a terror group Israel stopped providing food water and electricity to Gaza We are condemning the bombing of Israel Tharoor said at the event held at Kozhikode beach Tharoor who had previoulsy served as an UN diplomat said the ongoing air strikes in Gaza by Israel in response to the Hamas attack was disproportionate Reiterating Bapus words Tharoor said An eye for an eye will make the whole world blind India has always stood for peace since Gandhi He also highlighted that the ongoing crisis is not a Muslim issue but a human rights issue and said war knows no religion Israel calls their operation Swords of Iron but now those swords are dipped in the blood of children The bombing has caused a lot of injuries and innocent people are suffering and they are dying Many are living under suffocating occupation Tharoor said He said that over 6000 Palestinians and 300 Isrealis were killed in clashes in the area between 2008 and September this year and the number of those who died since October 7 however was much more While 1400 Israelis died in the Hamas terrorist attack many more were killed in Gaza when Israel responded to itInnocent civilians are dying Tharoor said Tharoor urged Israel to end the war and further appealed to the world to unite to end the human rights violations inflicted on the Palestinian people Now it is more than time to announce a ceasefire the Congress MP from Thiruvananthapuram said While addressing the rally IUML national general secretary PK Kunhalikutty said that the biggest weapon in the world is public opinion and that showing solidarity will bring results Children are dying We all are here to shed tears for the brutality in Gaza We have no weapons to send there or save them This rally will yield fruit because the biggest weapon in the world is public opinion Global leaders are joining in solidarity Thats how we also joined this Solidarity has made results here Killings should stop in Palestine he said IUML Party workers gathered in strength for Thursdays rally which was presided over by Kunhalikutty with Shashi Tharoor as Chief Guest IUML state president Panakkad Sayyid Sadiq Ali Shihab Thangal inaugurated the rally In his speech Thangal said Israels occupation has created Palestine conflict They are trying to survive They are trying the defend their land Stop genocide killings This conflict has started since 1947 Gandhi criticised Israeli occupation Nehru Manmohan Singh even Vajpayee also took a stand against the Israeli occupation of Palestine They all stood with justice The current government is trying to dilute that stand and make Israel look holy They are trying to whitewash Israel We should stand with marginalised Indias policy is to support the vulnerable people Israel is the biggest terrorist country Whoever is supporting Israel they are supporting terror Justice will rise over there thats why we are having this rally With our prayers let their wounds be healed the IUML leader said On attending the IUMLs solidarity rally Tharoor said India is one of the handful of countries that maintains ambassadors in both Israel and Palestine and enjoys good relations with both We should be a voice for peace amid the carnage After the October 7 attack on Israel from the Gaza Strip by Hamas Israeli Prime Minister Benjamin Netanyahu set up a war cabinet and the Israeli defence minister Yoav Gallant said they will launch a ground offensive on Gaza seeking to wipe off from the face of earth the Palestineterror group ANI '}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🔍 Filter Relevant Articles","metadata":{}},{"cell_type":"code","source":"def filter_relevant_articles(articles, keyword='Israel Hamas war'):\n    relevant_articles = [article for article in articles if keyword.lower() in article['content'].lower()]\n    return relevant_articles\n\nrelevant_articles = filter_relevant_articles(cleaned_articles)\n\nprint(f\"Total relevant articles: {len(relevant_articles)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:28:47.632964Z","iopub.execute_input":"2024-06-10T13:28:47.633338Z","iopub.status.idle":"2024-06-10T13:28:48.071406Z","shell.execute_reply.started":"2024-06-10T13:28:47.633307Z","shell.execute_reply":"2024-06-10T13:28:48.070409Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total relevant articles: 79\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🤖 Setup and Load the LLM","metadata":{}},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport transformers\nfrom transformers import BitsAndBytesConfig, AutoConfig, AutoModelForCausalLM, AutoTokenizer\n\nmodel_id = 'meta-llama/Llama-2-7b-chat-hf'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\n\n# hf_auth = '<add your access token here>'\nhf_auth = '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'\nmodel_config = AutoConfig.from_pretrained(model_id, use_auth_token=hf_auth)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n    use_auth_token=hf_auth\n)\n\nmodel.eval()\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_auth)\n\nprint(f\"Model loaded on {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:28:53.553692Z","iopub.execute_input":"2024-06-10T13:28:53.554399Z","iopub.status.idle":"2024-06-10T13:30:07.793219Z","shell.execute_reply.started":"2024-06-10T13:28:53.554361Z","shell.execute_reply":"2024-06-10T13:30:07.792201Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 121\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\n2024-06-10 13:29:05.114442: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-10 13:29:05.114566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-10 13:29:05.244972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c756fd09574a2f88a7b368a262e65b"}},"metadata":{}},{"name":"stderr","text":"You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Model loaded on cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🛑 Define Custom Stopping Criteria\n","metadata":{}},{"cell_type":"code","source":"from transformers import StoppingCriteria, StoppingCriteriaList\n\nstop_list = ['\\nHuman:', '\\n```\\n']\nstop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\nimport torch\n\nstop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n\nclass StopOnTokens(StoppingCriteria):\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n        for stop_ids in stop_token_ids:\n            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n                return True\n        return False\n\nstopping_criteria = StoppingCriteriaList([StopOnTokens()])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:12.925107Z","iopub.execute_input":"2024-06-10T13:30:12.925504Z","iopub.status.idle":"2024-06-10T13:30:12.935158Z","shell.execute_reply.started":"2024-06-10T13:30:12.925477Z","shell.execute_reply":"2024-06-10T13:30:12.934027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 📝 Initialize Text Generation Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ngenerate_text = pipeline(\n    model=model,\n    tokenizer=tokenizer,\n    return_full_text=True,  # Langchain expects the full text\n    task='text-generation',\n    stopping_criteria=stopping_criteria,\n    temperature=0.1,  # Randomness of outputs\n    max_new_tokens=512,  # Max number of tokens to generate\n    repetition_penalty=1.1  # To prevent output repetition\n)\n\n# Test the pipeline\nres = generate_text(\"What happened at the Al-Shifa Hospital?\")\nprint(res[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:18.113113Z","iopub.execute_input":"2024-06-10T13:30:18.113902Z","iopub.status.idle":"2024-06-10T13:30:35.761365Z","shell.execute_reply.started":"2024-06-10T13:30:18.113868Z","shell.execute_reply":"2024-06-10T13:30:35.760327Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"What happened at the Al-Shifa Hospital?\n nobody knows. The Sudanese government has been tight-lipped about the incident, and there have been conflicting reports about what exactly happened. Some sources say that the attack was carried out by a group of armed men who entered the hospital and opened fire on patients and medical staff. Others claim that the attack was staged as part of a larger conspiracy to discredit the Sudanese government. Whatever the truth may be, it is clear that the attack on the Al-Shifa Hospital was a horrific act of violence that left many innocent people dead or injured. It is important that we continue to investigate this incident and hold those responsible accountable for their actions.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🔗 Integrate with LangChain","metadata":{}},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\n\nllm = HuggingFacePipeline(pipeline=generate_text)\n\n# Test LangChain integration\nresponse = llm(prompt=\"What happened at the Al-Shifa Hospital?\")\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:30:41.583682Z","iopub.execute_input":"2024-06-10T13:30:41.584141Z","iopub.status.idle":"2024-06-10T13:31:17.121541Z","shell.execute_reply.started":"2024-06-10T13:30:41.584107Z","shell.execute_reply":"2024-06-10T13:31:17.120320Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n","output_type":"stream"},{"name":"stdout","text":"\n Unterscheidung zwischen \"Al-Shifa\" und \"Al Shifa\"\n\nThe Al-Shifa Hospital is a major medical facility located in the capital city of Riyadh, Saudi Arabia. On April 14, 2015, a fire broke out at the hospital, resulting in significant damage to the building and loss of life. The exact cause of the fire is still under investigation, but it is believed to have been caused by an electrical malfunction.\n\nThe incident was widely reported in the local media, with many news outlets providing updates on the situation. According to reports, the fire started in the hospital's intensive care unit (ICU) and quickly spread to other areas of the building. Firefighters were able to contain the blaze and prevent it from spreading to other parts of the city, but not before several people had died and many more were injured.\n\nIn the aftermath of the fire, there were concerns about the safety of patients and staff at the hospital. However, officials assured the public that all necessary measures were being taken to ensure their safety and well-being. The hospital was evacuated as a precautionary measure, and patients and staff were relocated to other facilities until the building could be deemed safe for use again.\n\nThe Al-Shifa Hospital fire was a tragic event that had far-reaching consequences for the community. It highlighted the importance of proper safety protocols and emergency preparedness measures, and served as a reminder of the need for ongoing investment in healthcare infrastructure.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 🌟 Retrieval of Data from Websites\n","metadata":{}},{"cell_type":"code","source":"from langchain.document_loaders import WebBaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import ConversationalRetrievalChain\n\nweb_links = [\"https://en.wikipedia.org/wiki/Israel%E2%80%93Hamas_war\", \"https://edition.cnn.com/middleeast/live-news/israel-hamas-war-gaza-news-06-09-24/index.html\", \"https://en.wikipedia.org/wiki/Al-Shifa_Hospital_siege#:~:text=After%20a%20two%20week%20siege,hospital%2C%20including%20in%20mass%20graves.\"]\n\nloader = WebBaseLoader(web_links)\ndocuments = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\nall_splits = text_splitter.split_documents(documents)\n\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cpu\"}  # Use CPU instead of CUDA\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n\n# Storing embeddings in the vector store\nvectorstore = FAISS.from_documents(all_splits, embeddings)\n\nchain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n\nchat_history = []\n\nquery = \"What happened at the Al-Shifa Hospital?\"\nresult = chain({\"question\": query, \"chat_history\": chat_history})\n\nprint(result['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T13:36:02.563632Z","iopub.execute_input":"2024-06-10T13:36:02.564782Z","iopub.status.idle":"2024-06-10T13:39:48.373340Z","shell.execute_reply.started":"2024-06-10T13:36:02.564730Z","shell.execute_reply":"2024-06-10T13:39:48.370974Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d6c759c4f947f09030d123bdf614bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e229544ddc1149af95a0928ce63c43cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94f8b200267a4246a1c39c2d65e6a333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81b421611f624a4eb31905ae357f959a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116b95fc0d6f4327ad2a35cc85b99794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5d34b971e45463e830471d8df9a555d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da261c363e5406bbd408f9d43c67b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76d7bdd3d0c4eb49d9debbc86818c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70cf50a04a034a74b37fcb250a1682a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78409647ff0545e69aa2470a6e5a9e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa78375f467b4bb98a530faa3858d91b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n","output_type":"stream"},{"name":"stdout","text":" Based on the provided text, it appears that the Israeli military launched a raid on the Al-Shifa Hospital, resulting in the deaths of patients and medical staff, as well as the destruction of the hospital. Witnesses reported seeing Israeli forces firing at the hospital and detaining medical staff and patients. The World Health Organization reported that 21 patients had died during the raid, and Israeli forces claimed to have found weapons hidden in patients' pillows and beds. The hospital was left with blown out windows and blackened concrete walls after the Israeli forces withdrew.\n","output_type":"stream"}]}]}