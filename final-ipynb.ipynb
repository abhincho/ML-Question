{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T05:54:39.451633Z","iopub.status.busy":"2024-06-08T05:54:39.451248Z","iopub.status.idle":"2024-06-08T05:55:23.578233Z","shell.execute_reply":"2024-06-08T05:55:23.576938Z","shell.execute_reply.started":"2024-06-08T05:54:39.451593Z"},"trusted":true},"outputs":[],"source":["!pip install gdown transformers tabulate\n","\n","import gdown\n","import json\n","import re\n","from collections import defaultdict\n","import datetime\n","import matplotlib.pyplot as plt\n","from transformers import pipeline, BartForConditionalGeneration, BartTokenizer\n","from tabulate import tabulate\n","\n","file_url = \"https://drive.google.com/uc?export=download&id=1q6KVw4LD_rnXKVViVkBpdTyedHdQvtkk\"\n","output = 'news_articles.json'\n","gdown.download(file_url, output, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def summarize_titles(titles, max_length=20):\n","    model_name = \"facebook/bart-large-cnn\"\n","    tokenizer = BartTokenizer.from_pretrained(model_name)\n","    model = BartForConditionalGeneration.from_pretrained(model_name)\n","    \n","    summaries = []\n","    chunk_size = min(5, len(titles))  \n","    for title_chunk in [titles[i:i+chunk_size] for i in range(0, len(titles), chunk_size)]:\n","        title_chunk = [title[:512] for title in title_chunk] \n","        inputs = tokenizer.prepare_seq2seq_batch(title_chunk, truncation=True, padding='longest', return_tensors=\"pt\")\n","        summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=max_length, length_penalty=2.0, early_stopping=True)\n","        chunk_summaries = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n","        summaries.extend(chunk_summaries)\n","    \n","    return summaries\n","model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n","nlp = pipeline(\"ner\", model=model_name, aggregation_strategy=\"simple\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T05:59:15.932465Z","iopub.status.busy":"2024-06-08T05:59:15.932007Z","iopub.status.idle":"2024-06-08T05:59:18.833070Z","shell.execute_reply":"2024-06-08T05:59:18.831682Z","shell.execute_reply.started":"2024-06-08T05:59:15.932430Z"},"trusted":true},"outputs":[],"source":["with open('news_articles.json') as f:\n","    articles = json.load(f)\n","print(f\"Loaded {len(articles)} articles.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T05:59:22.078999Z","iopub.status.busy":"2024-06-08T05:59:22.078530Z","iopub.status.idle":"2024-06-08T05:59:22.104822Z","shell.execute_reply":"2024-06-08T05:59:22.103406Z","shell.execute_reply.started":"2024-06-08T05:59:22.078963Z"},"trusted":true},"outputs":[],"source":["def clean_text(text):\n","    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n","    text = text.lower()\n","    return text\n","\n","for article in articles:\n","    article['cleaned_text'] = clean_text(article['articleBody'])\n","\n","print(\"Text cleaning complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T05:59:25.150281Z","iopub.status.busy":"2024-06-08T05:59:25.149782Z","iopub.status.idle":"2024-06-08T05:59:25.159238Z","shell.execute_reply":"2024-06-08T05:59:25.157831Z","shell.execute_reply.started":"2024-06-08T05:59:25.150244Z"},"trusted":true},"outputs":[],"source":["keywords = [\"israel\", \"hamas\", \"gaza\", \"palestine\", \"war\",\"airstrikes\",\"rafah\",\"yemen\"]\n","\n","def is_relevant(article):\n","    for keyword in keywords:\n","        if keyword in article['cleaned_text']:\n","            return True\n","    return False\n","\n","relevant_articles = [article for article in articles if is_relevant(article)]\n","\n","print(f\"Found {len(relevant_articles)} relevant articles.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T05:59:28.271724Z","iopub.status.busy":"2024-06-08T05:59:28.271286Z","iopub.status.idle":"2024-06-08T06:03:41.842019Z","shell.execute_reply":"2024-06-08T06:03:41.840646Z","shell.execute_reply.started":"2024-06-08T05:59:28.271683Z"},"trusted":true},"outputs":[],"source":["\n","\n","def extract_events(text):\n","    events = nlp(text)\n","    return events\n","\n","for article in relevant_articles:\n","    article['events'] = extract_events(article['cleaned_text'])\n","\n","print(\"Event extraction complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T06:03:41.844531Z","iopub.status.busy":"2024-06-08T06:03:41.844168Z","iopub.status.idle":"2024-06-08T06:03:41.856274Z","shell.execute_reply":"2024-06-08T06:03:41.855058Z","shell.execute_reply.started":"2024-06-08T06:03:41.844498Z"},"trusted":true},"outputs":[],"source":["timeline = defaultdict(list)\n","\n","for article in relevant_articles:\n","    if 'dateModified' in article and '$date' in article['dateModified']:\n","        date = article['dateModified']['$date'][:10]\n","    elif 'scrapedDate' in article and '$date' in article['scrapedDate']:\n","        date = article['scrapedDate']['$date'][:10]\n","    else:\n","        continue\n","    \n","    date_obj = datetime.datetime.strptime(date, '%Y-%m-%d')\n","    for event in article['events']:\n","        event_name = article['title']  # Use article title as event name\n","        timeline[date_obj].append((event_name, event))\n","\n","print(\"Timeline creation complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-08T06:03:41.858318Z","iopub.status.busy":"2024-06-08T06:03:41.857838Z","iopub.status.idle":"2024-06-08T06:04:23.636442Z","shell.execute_reply":"2024-06-08T06:04:23.635200Z","shell.execute_reply.started":"2024-06-08T06:03:41.858277Z"},"trusted":true},"outputs":[],"source":["timeline_table = []\n","\n","for date, events in timeline.items():\n","    date_str = date.strftime('%Y-%m-%d')\n","    num_events = len(events)\n","    titles = [event[0] for event in events]  \n","    combined_title = \", \".join(titles)\n","    summary = summarize_titles([combined_title])[0]\n","    timeline_table.append([date_str, num_events, summary])\n","    #timeline_table.append([date_str,  summary])\n","\n","print(tabulate(timeline_table, headers=['Date', 'Number of Events',\"Event Occured\"], tablefmt='grid'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
